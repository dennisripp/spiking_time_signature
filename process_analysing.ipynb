{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking shapes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 149529.55it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 94466.31it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 191958.99it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 95979.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 123908.54it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 113359.57it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 37549.72it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 134003.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "Loading and preprocessing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.43it/s]\n",
      "\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.38s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.08it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with preprocessing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @title smulti-threaded sample analysis system\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from brian2 import *\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except ImportError:\n",
    "    !pip3 install ipywidgets\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "fixed_timesteps = 1001\n",
    "\n",
    "def get_length(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    return mfccs.shape[1]\n",
    "\n",
    "def determine_fixed_length(directory):\n",
    "    file_paths = []\n",
    "\n",
    "    for subdir in ['1_4', '2_4', '3_4', '4_4']:\n",
    "        for file in tqdm(os.listdir(os.path.join(directory, subdir))):\n",
    "            file_path = os.path.join(directory, subdir, file)\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "    # Utilize multiprocessing for faster computation\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        lengths = list(executor.map(get_length, file_paths))\n",
    "\n",
    "    return min(lengths)\n",
    "\n",
    "def parallel_data_loader(directories):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(parallel_load_and_preprocess, directories), total=len(directories)))\n",
    "    return results\n",
    "\n",
    "def load_and_preprocess_data_subdir(args):\n",
    "    directory, subdir = args\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in os.listdir(os.path.join(directory, subdir)):\n",
    "        file_path = os.path.join(directory, subdir, file)\n",
    "        processed_data = load_audio(file_path)\n",
    "        data.append(processed_data)\n",
    "        label = ['1_4', '2_4', '3_4', '4_4'].index(subdir)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "def parallel_load_and_preprocess(directory):\n",
    "    # Create a pool of processes\n",
    "    pool = Pool(cpu_count())\n",
    "\n",
    "    # Create a list of tasks\n",
    "    tasks = [(directory, time_sig) for time_sig in ['1_4', '2_4', '3_4', '4_4']]\n",
    "\n",
    "    # Use imap_unordered to distribute the work among the processes\n",
    "    results = list(tqdm(pool.imap_unordered(load_and_preprocess_data_subdir, tasks), total=len(tasks), mininterval=0.01))\n",
    "\n",
    "    # Close the pool and wait for all processes to finish\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Combine results\n",
    "    combined_data = []\n",
    "    combined_labels = []\n",
    "    \n",
    "    for data, labels in results:\n",
    "        combined_data.extend(data)\n",
    "        combined_labels.extend(labels)\n",
    "    \n",
    "    return combined_data, combined_labels\n",
    "\n",
    "\n",
    "def adjust_fixed_length(features, timesteps):\n",
    "    # If the array is 1-dimensional\n",
    "    if len(features.shape) == 1:\n",
    "        if features.shape[0] > timesteps:\n",
    "            return features[:timesteps]\n",
    "        elif features.shape[0] < timesteps:\n",
    "            padding = np.zeros(timesteps - features.shape[0])\n",
    "            return np.hstack((features, padding))\n",
    "        return features\n",
    "    # If the array is 2-dimensional\n",
    "    else:\n",
    "        # If the time axis of the 2D array is greater than timesteps, crop it.\n",
    "        if features.shape[1] > timesteps:\n",
    "            return features[:, :timesteps]\n",
    "        # If the time axis of the 2D array is less than timesteps, pad it.\n",
    "        elif features.shape[1] < timesteps:\n",
    "            padding = np.zeros((features.shape[0], timesteps - features.shape[1]))\n",
    "            return np.hstack((features, padding))\n",
    "        return features\n",
    "\n",
    "# Convert real-valued features to Poisson spike trains\n",
    "def poisson_spike_encoding(data, duration=10, dt=1*ms):\n",
    "    # Assuming data is normalized between 0 and 1\n",
    "    rates = data * (1.0/dt)\n",
    "    spikes = (np.random.rand(*data.shape) < rates*dt).astype(float)\n",
    "    return spikes\n",
    "\n",
    "def temporal_binning(data, bin_size):\n",
    "    \"\"\"\n",
    "    Bins the data into chunks of bin_size and returns the average of each chunk.\n",
    "    \"\"\"\n",
    "    # Split the data into chunks of bin_size\n",
    "    binned_data = [np.mean(data[i:i+bin_size]) for i in range(0, len(data), bin_size)]\n",
    "    return np.array(binned_data)\n",
    "\n",
    "def rate_based_encoding(data, min_freq, max_freq):\n",
    "    \"\"\"\n",
    "    Convert onset strengths to spike frequencies.\n",
    "    data: The input data (should be normalized to [0, 1])\n",
    "    min_freq: The minimum spike frequency (corresponds to data value of 0)\n",
    "    max_freq: The maximum spike frequency (corresponds to data value of 1)\n",
    "    Returns: Spike frequencies corresponding to input data\n",
    "    \"\"\"\n",
    "    return min_freq + data * (max_freq - min_freq)\n",
    "\n",
    "def extract_bpm_and_instrument(file_path):\n",
    "    match = re.search(r\"instrument_(\\d+)_bpm_(\\d+)_duration_(\\d+)_noise_([\\d.]+)\", file_path)\n",
    "    if match:\n",
    "        instrument = match.group(1)\n",
    "        bpm = match.group(2)\n",
    "        duration = match.group(3)\n",
    "        noise = match.group(4)\n",
    "        return instrument, bpm, duration, noise\n",
    "    return None, None, None, None\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    \"\"\"Compute moving average\"\"\"\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "\n",
    "def load_audio(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=22050)  # setting sr ensures all files are resampled to this rate\n",
    "    return [y, sr, file_path]\n",
    "\n",
    "# Process the audio file into desired features\n",
    "# Process the audio file into desired features\n",
    "def preprocess_audio(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=22050)  # setting sr ensures all files are resampled to this rate\n",
    "    time_signature = file_path.split('/')[-2].replace('_', '/')\n",
    "    instrument, bpm = extract_bpm_and_instrument(file_path)\n",
    "\n",
    "    # Extracting onset strength\n",
    "    onset_strength = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    \n",
    "    # Extracting tempogram\n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=onset_strength, sr=sr)\n",
    "    \n",
    "    # Extracting tempogram\n",
    "    tempogram_cropped = librosa.feature.tempogram(onset_envelope=onset_strength[20:], sr=sr)\n",
    "    \n",
    "    # Adjust the time axis of each feature to fixed_timesteps\n",
    "    onset_strength_fixed = adjust_fixed_length(onset_strength, fixed_timesteps)\n",
    "    tempogram_fixed = adjust_fixed_length(tempogram, fixed_timesteps)\n",
    "\n",
    "    # Stacking features horizontally\n",
    "    combined_features = np.vstack(poisson_spike_encoding(onset_strength))\n",
    "    \n",
    "    # Normalize to range [0, 1]\n",
    "    encoded_features = (combined_features - np.min(combined_features)) / (np.max(combined_features) - np.min(combined_features))\n",
    "    \n",
    "        # Plotting\n",
    "    plt.figure(figsize=(12, 14))\n",
    "    plt.title('audio  with {time_signature} time signature, {bpm} bpm, and instrument {instrument}')\n",
    "\n",
    "    rows = 6\n",
    "    # 1. Raw audio\n",
    "    plt.subplot(rows, 1, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Raw Audio')\n",
    "\n",
    "    # 2. Onset strength\n",
    "    plt.subplot(rows, 1, 2)\n",
    "    plt.plot(onset_strength_fixed)\n",
    "    plt.title('Onset Strength fixed size')\n",
    "    \n",
    "    # 2. Onset strength\n",
    "    plt.subplot(rows, 1, 3)\n",
    "    onset_strength_normalized = (onset_strength[20:] - np.min(onset_strength[20:])) / (np.max(onset_strength[20:]) - np.min(onset_strength[20:]))\n",
    "    plt.plot(onset_strength_normalized)\n",
    "    plt.title('Onset Strength normalized and cropped')\n",
    "    \n",
    "    # Add a plot for averaged onset strength\n",
    "    plt.subplot(rows, 1, 4)\n",
    "    averaged_onset = moving_average(onset_strength_normalized, window_size=5)  # using a window size of 10, adjust as needed\n",
    "    plt.plot(averaged_onset)\n",
    "    plt.title('Averaged Onset Strength')\n",
    "    \n",
    "    # 3. Tempogram\n",
    "    plt.subplot(rows, 1, 5)\n",
    "    librosa.display.specshow(tempogram_fixed, sr=sr, x_axis='time', y_axis='tempo')\n",
    "    plt.title('Tempogram fixed')\n",
    "    \n",
    "        # 3. Tempogram\n",
    "    plt.subplot(rows, 1, 6)\n",
    "    librosa.display.specshow(tempogram_cropped, sr=sr, x_axis='time', y_axis='tempo')\n",
    "    plt.title('Tempogram cropped')\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output_processing_noise_avg/{time_signature.replace(\"/\", \"_\")}_BPM{bpm}_noise.png')\n",
    "    \n",
    "    return encoded_features[20:]\n",
    "\n",
    "\n",
    "def count_files(directory):\n",
    "    return sum([len(files) for _, _, files in os.walk(directory)])\n",
    "\n",
    "# Current directory\n",
    "directory = '.'\n",
    "\n",
    "# Loop through all files in the current directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the filename ends with '.png' and contains 'spike_train'\n",
    "    if filename.endswith('.png') and 'spike_train' in filename:\n",
    "        # Construct the full file path\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Remove the file\n",
    "        os.remove(filepath)\n",
    "        print(f\"Deleted: {filename}\", end='\\r')\n",
    "        \n",
    "\n",
    "# checking shapes\n",
    "print(\"Checking shapes...\")\n",
    "fixed_timesteps = determine_fixed_length('training_data')\n",
    "print(fixed_timesteps)\n",
    "fixed_timesteps2 = determine_fixed_length('validation_data')\n",
    "print(fixed_timesteps2)\n",
    "fixed_timesteps = max(fixed_timesteps, fixed_timesteps2)\n",
    "\n",
    "\n",
    "# 1. Load and preprocess data\n",
    "print(\"Loading and preprocessing training data...\")\n",
    "directories = ['training_data', 'validation_data']\n",
    "training_data_results, validation_data_results = parallel_data_loader(directories)\n",
    "\n",
    "training_data, training_labels = training_data_results\n",
    "validation_data, validation_labels = validation_data_results\n",
    "print(\"\\nDone with preprocessing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2268ea73f5a43239244ad81c175802b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Item No.', max=79), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.signal\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "class LIFNeuron:\n",
    "    def __init__(self, tau_m=20.0, v_rest=0.0, v_threshold=1.0, v_reset=0.0, r_m=1.0, dt=1.0):\n",
    "        self.tau_m = tau_m\n",
    "        self.v_rest = v_rest\n",
    "        self.v_threshold = v_threshold\n",
    "        self.v_reset = v_reset\n",
    "        self.r_m = r_m\n",
    "        self.dt = dt\n",
    "        self.v = v_rest\n",
    "\n",
    "    def step(self, i):\n",
    "        dv = (-self.v + self.v_rest + self.r_m * i) / self.tau_m * self.dt\n",
    "        self.v += dv\n",
    "        spike = 0\n",
    "        if self.v >= self.v_threshold:\n",
    "            spike = 1\n",
    "            self.v = self.v_reset\n",
    "        return spike\n",
    "    \n",
    "def generate_lif_spikes(data, neuron):\n",
    "    spikes = []\n",
    "    for i in data:\n",
    "        spike = neuron.step(i)\n",
    "        spikes.append(spike)\n",
    "    return np.array(spikes)\n",
    "\n",
    "def smooth_using_savgol(data, window_size, polynomial_order=3):\n",
    "    return savgol_filter(data, window_size, polynomial_order)\n",
    "\n",
    "# Convert real-valued features to Poisson spike trains\n",
    "def poisson_spike_encoding(data, duration=10, dt=1*ms):\n",
    "    # Assuming data is normalized between 0 and 1\n",
    "    rates = data * (1.0/dt)\n",
    "    spikes = (np.random.rand(*data.shape) < rates*dt).astype(float)\n",
    "    return spikes\n",
    "\n",
    "def low_pass_filter(y, sr, cutoff_freq):\n",
    "    nyq = 0.5 * sr  # Nyquist frequency\n",
    "    normal_cutoff = cutoff_freq / nyq\n",
    "    b, a = scipy.signal.butter(6, normal_cutoff, btype='low', analog=False)\n",
    "    return scipy.signal.filtfilt(b, a, y)\n",
    "\n",
    "def high_pass_filter(y, sr, cutoff_freq):\n",
    "    nyq = 0.5 * sr  # Nyquist frequency\n",
    "    normal_cutoff = cutoff_freq / nyq\n",
    "    b, a = scipy.signal.butter(6, normal_cutoff, btype='high', analog=False)\n",
    "    return scipy.signal.filtfilt(b, a, y)\n",
    "\n",
    "def normalize_data(data):\n",
    "    \"\"\"Normalisiert eine Liste von Werten zwischen 0 und 1.\"\"\"\n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    return [(val - min_val) / (max_val - min_val) for val in data]\n",
    "\n",
    "def plot_pixel_spectra_norm(item_no, window_size, tau_m, v_rest, v_threshold, v_reset, r_m, dt, high_pass_cutoff):\n",
    "    y = training_data[item_no][0]\n",
    "    sr = training_data[item_no][1]\n",
    "    file_path = training_data[item_no][2]\n",
    "    # Extract the MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y[20:], sr=sr)\n",
    "    # y = low_pass_filter(y, sr, low_pass_cutoff)\n",
    "    # y = high_pass_filter(y, sr, high_pass_cutoff)\n",
    "    \n",
    "    time_signature = file_path.split('/')[-2].replace('_', '/')\n",
    "    instrument, bpm, duration, noise = extract_bpm_and_instrument(file_path)\n",
    "    print(f\"time signature: {time_signature} BPM:{bpm} Noise:{noise} sampling rate: {sr} \", end='\\r')\n",
    "\n",
    "    # Extracting onset strength\n",
    "    onset_strength = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    \n",
    "    # Extracting tempogram\n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=onset_strength, sr=sr)\n",
    "    \n",
    "    # Extracting tempogram\n",
    "    tempogram_cropped = librosa.feature.tempogram(onset_envelope=onset_strength[20:], sr=sr)\n",
    "    \n",
    "    # Adjust the time axis of each feature to fixed_timesteps\n",
    "    onset_strength_fixed = adjust_fixed_length(onset_strength, fixed_timesteps)\n",
    "    tempogram_fixed = adjust_fixed_length(tempogram, fixed_timesteps)\n",
    "\n",
    "    # Stacking features horizontally\n",
    "    combined_features = np.vstack(poisson_spike_encoding(onset_strength))\n",
    "    \n",
    "    # Normalize to range [0, 1]\n",
    "    encoded_features = (combined_features - np.min(combined_features)) / (np.max(combined_features) - np.min(combined_features))\n",
    "    \n",
    "    onset_strength_normalized = (onset_strength[20:] - np.min(onset_strength[20:])) / (np.max(onset_strength[20:]) - np.min(onset_strength[20:]))\n",
    "\n",
    "    averaged_onset = moving_average(onset_strength_normalized, window_size=window_size)  # using a window size of 10, adjust as needed\n",
    "    normalized_averaged_onset = normalize_data(averaged_onset)\n",
    "    \n",
    "    global_tempo = librosa.feature.rhythm.tempo(onset_envelope=onset_strength, sr=sr)[0]\n",
    "    dtempo = librosa.feature.rhythm.tempo(onset_envelope=onset_strength, sr=sr, aggregate=None)\n",
    "    \n",
    "        # Plotting\n",
    "    plt.figure(figsize=(12, 14))\n",
    "    plt.title('audio  with {time_signature} time signature, {bpm} bpm, and instrument {instrument}')\n",
    "\n",
    "    rows = 6\n",
    "    # 1. Raw audio\n",
    "    plt.subplot(rows, 1, 1)\n",
    "    # Prepare time axes for raw audio and onset strength\n",
    "    time_audio = np.linspace(0, len(y) / sr, len(y))\n",
    "    hop_length = 512  # default hop length in librosa for onset_strength\n",
    "    time_onset = np.linspace(0, len(y) / sr, len(normalize_data(onset_strength)))\n",
    "    # Plot raw audio\n",
    "    # librosa.display.waveshow(y[20:], sr=sr, alpha=0.7, label='Raw Audio')\n",
    "\n",
    "    # # Plot onset strength, normalized and scaled to match the raw audio amplitude for visualization\n",
    "    # plt.plot(onset_strength[20:], color='r', label='Onset Strength')\n",
    "    \n",
    "\n",
    "    # Plot raw audio\n",
    "    plt.plot(time_audio, normalize_data(y), label='Raw Audio', alpha=0.7)\n",
    "\n",
    "    # Plot onset strength (scaled)\n",
    "    plt.plot(time_onset, normalize_data(onset_strength), label='Onset Strength (scaled)', alpha=0.7, color='r')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time (s)')\n",
    "\n",
    "    plt.title(f'Raw Audio and Onset Strength, predicted BPM = {global_tempo}, actual BPM = {bpm}, instrument {instrument} and time signature {time_signature}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Frequency spectrum\n",
    "    plt.subplot(rows, 1, 2)\n",
    "    # fourier = np.fft.fft(y[20:])\n",
    "    # n = len(fourier)\n",
    "    # frequencies = np.fft.fftfreq(n, 1/sr)  # <-- Adjusted this line\n",
    "    # fft_x = frequencies[:n//2]\n",
    "    # fft_y = np.abs(fourier)[:n//2]\n",
    "    # plt.plot(fft_x, fft_y)\n",
    "    # plt.title('Frequency Spectrum')\n",
    "    # plt.xlabel('Frequency (Hz)')\n",
    "    # plt.ylabel('Magnitude')\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    plt.title('MFCC')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('MFCC Coefficients')\n",
    "    \n",
    "    \n",
    "    # 3. Frequency spectrum after high-pass filtering\n",
    "    plt.subplot(rows, 1, 3)\n",
    "    y_high_pass = high_pass_filter(y[20:], sr, high_pass_cutoff)\n",
    "    fourier_high_pass = np.fft.fft(y_high_pass)\n",
    "    n_high_pass = len(fourier_high_pass)\n",
    "    frequencies_high_pass = np.fft.fftfreq(n_high_pass, 1/sr) \n",
    "    plt.plot(frequencies_high_pass[:n_high_pass//2], np.abs(fourier_high_pass)[:n_high_pass//2])\n",
    "    plt.title(f'Frequency Spectrum after high-pass filter at {int(high_pass_cutoff)} Hz')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "\n",
    "    plt.tight_layout()  # <-- Makes the layout cleaner\n",
    "    #plt.legend()\n",
    "    \n",
    "    # 2. Onset strength\n",
    "    # plt.subplot(rows, 1, 2)\n",
    "    # plt.plot(onset_strength_fixed, label='Onset Strength')\n",
    "    # poisson_encoded = poisson_spike_encoding(onset_strength_fixed.reshape(1,-1))\n",
    "    # plt.plot(poisson_encoded[0], label='Poisson Spike Train', linestyle=':')\n",
    "    # plt.title('Onset Strength fixed size')\n",
    "    \n",
    "    # 2. Onset strength\n",
    "    plt.subplot(rows, 1, 4)\n",
    "    plt.plot(onset_strength_normalized, label='Onset Strength', alpha=0.7)\n",
    "    poisson_encoded = poisson_spike_encoding(onset_strength_normalized.reshape(1,-1), dt=dt*ms)\n",
    "    # Calculate the spike count\n",
    "    spike_count = np.sum(poisson_encoded)\n",
    "    plt.plot(poisson_encoded[0], label='Poisson Spike Train', linestyle=':', color='g')\n",
    "    plt.title(f'Onset Strength fixed size with Poisson Spike Train - Spike Count: {int(spike_count)}')    \n",
    "    plt.legend()\n",
    "    # 2. Onset strength\n",
    "    plt.subplot(rows, 1, 5)\n",
    "    # plt.plot(onset_strength_normalized)\n",
    "   \n",
    "    lif_neuron = LIFNeuron(tau_m=tau_m, v_rest=v_rest, v_threshold=v_threshold, v_reset=v_reset, r_m=r_m, dt=dt)\n",
    "    lif_spikes = generate_lif_spikes(onset_strength_normalized, lif_neuron)\n",
    "    spike_count = np.sum(lif_spikes)\n",
    "        # 3. Onset strength with LIF spike train\n",
    "    plt.plot(onset_strength_normalized, label='Onset Strength', alpha=0.7)\n",
    "    plt.plot(lif_spikes, label='LIF Spike Train', linestyle=':', color='r')\n",
    "    plt.title(f'Onset Strength with LIF Spike Train, Spike Count: {int(spike_count)}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # # Add a plot for averaged onset strength\n",
    "    # plt.subplot(rows, 1, 4)\n",
    "    # plt.plot(normalized_averaged_onset)\n",
    "    # plt.title('Averaged Onset Strength')\n",
    "    \n",
    "    # 3. Tempogram\n",
    "    plt.subplot(rows, 1, 6)\n",
    "    librosa.display.specshow(tempogram_fixed, sr=sr, x_axis='time', y_axis='tempo')\n",
    "    plt.title('Tempogram fixed')\n",
    "    \n",
    "    #     # 3. Tempogram\n",
    "    # plt.subplot(rows, 1, 6)\n",
    "    # librosa.display.specshow(tempogram_cropped, sr=sr, x_axis='time', y_axis='tempo')\n",
    "    # plt.title('Tempogram cropped')\n",
    "    \n",
    "        # lif_neuron = LIFNeuron(tau_m=5, v_rest=0.0, v_threshold=0.7, v_reset=0.0, r_m=1.0, dt=10)\n",
    "\n",
    "    plt.figtext(0.15, 0.02, f\"Item No: {item_no}, Window Size: {window_size}, tau_m: {tau_m}, v_rest: {v_rest}, \"\n",
    "                        f\"v_threshold: {v_threshold}, v_reset: {v_reset}, r_m: {r_m}, dt: {dt}, \"\n",
    "                        f\"high_pass_cutoff: {high_pass_cutoff}\", ha=\"left\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plot_with_params.png')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def interactive_plot_spec_norm(item_no, window_size, tau_m, v_rest, v_threshold, v_reset, r_m, dt, high_pass_cutoff):\n",
    "    plot_pixel_spectra_norm(item_no, window_size, tau_m, v_rest, v_threshold, v_reset, r_m, dt, high_pass_cutoff)\n",
    "\n",
    "\n",
    "if widgets is not None:\n",
    "    widgets.interact(\n",
    "        interactive_plot_spec_norm,\n",
    "        item_no=widgets.IntSlider(min=0, max=len(training_data)-1, value=0, step=1, continuous_update=False, description=\"Item No.\"),\n",
    "        window_size=widgets.IntSlider(min=1, max=400, value=10, step=1, continuous_update=False, description=\"avg window size\"),\n",
    "        tau_m=widgets.FloatSlider(min=1.0, max=100.0, value=5.0, step=0.5, continuous_update=False, description=\"tau_m\"),\n",
    "        v_rest=widgets.FloatSlider(min=0.0, max=1.0, value=0.0, step=0.1, continuous_update=False, description=\"v_rest\"),\n",
    "        v_threshold=widgets.FloatSlider(min=0.0, max=1.0, value=0.6, step=0.1, continuous_update=False, description=\"v_threshold\"),\n",
    "        v_reset=widgets.FloatSlider(min=0.0, max=1.0, value=0.0, step=0.1, continuous_update=False, description=\"v_reset\"),\n",
    "        r_m=widgets.FloatSlider(min=0.1, max=1.0, value=1.0, step=0.1, continuous_update=False, description=\"r_m\"),\n",
    "        dt=widgets.FloatSlider(min=0.1, max=100.0, value=10.0, step=1.0, continuous_update=False, description=\"dt\"),\n",
    "        high_pass_cutoff=widgets.FloatSlider(min=10.0, max=1000.0, value=500.0, step=10.0, continuous_update=False, description=\"high_pass_cutoff [Hz]\"),\n",
    "    );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
